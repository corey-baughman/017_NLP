{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687291ed-de98-403f-854b-cb11a38d5041",
   "metadata": {},
   "source": [
    "# NLP Prepare Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14da507-544a-48dd-9ae9-60d24f63e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# text and file handling\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "# NLP\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# local modules\n",
    "from acquire import (get_blog_articles_data, \n",
    "                     get_news_articles_data)\n",
    "import prepare as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4925d741-b979-4b27-8a42-8397f4945261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/donq/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/donq/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d44656f-7eb7-44e2-8ee7-f37cc9c5a1ed",
   "metadata": {},
   "source": [
    "### **Goal:** \n",
    "- The end result of this exercise should be a file named prepare.py that defines the requested functions. \n",
    "- In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3f09f-56b0-44e0-87c5-43850189bcf7",
   "metadata": {},
   "source": [
    "### **Acquisition**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ad0fc-55d2-4767-adfd-e184da0202ca",
   "metadata": {},
   "source": [
    "Going to go ahead and import both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da3fca2-ba59-48b8-8400-2dbe487213d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df = get_blog_articles_data()\n",
    "news_df = get_news_articles_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d46b58-3dba-402b-9972-ff06a8d5720f",
   "metadata": {},
   "source": [
    "### **Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead06f8-529d-4f81-9f51-8e5319b9340a",
   "metadata": {},
   "source": [
    "##### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "   - Lowercase everything\n",
    "   - Normalize unicode characters\n",
    "   - Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcef5ecd-d3e6-428d-8059-23eedd31e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I need texting to Test some thing's out jump jumped jumping! have has had\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e0d5ee-e699-40bc-9960-51dea0b8e171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i need texting to test some things out jump jumped jumping have has had'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = p.basic_clean(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc51bf81-a830-4ded-8d7a-da56e716ead2",
   "metadata": {},
   "source": [
    "##### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e074824-5d62-4897-824f-e53356d0e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = p.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e256b1-ae3f-4ce3-9115-d66356350ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i need texting to test some things out jump jumped jumping have has had'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f64cb2-af1c-4908-b5c6-18857fd73629",
   "metadata": {},
   "source": [
    "##### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d515e278-f722-46fa-9838-87d29359d0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i need text to test some thing out jump jump jump have ha had'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed = p.stem(tokenized)\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a1d350-fdea-46e2-b5c1-0e02ab612749",
   "metadata": {},
   "source": [
    "##### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a252f8f-5479-4f45-8456-3469c4dbf8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i need texting to test some thing out jump jump jump have have have'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized = p.lemmatize(tokenized)\n",
    "lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482a30c2-9ace-4fcb-805d-a60876e955d2",
   "metadata": {},
   "source": [
    "##### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dec1dfc-f93b-48a7-8d1b-1501e6270cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'need texting test thing jump jump jump'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.remove_stopwords(lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965f81e-409f-4536-a73f-b5e7a3017e0d",
   "metadata": {},
   "source": [
    "##### 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe5b453-828a-4a82-a35f-d3eb5cb6cca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WhatsApp responds to int'l calls scam, announc...</td>\n",
       "      <td>WhatsApp has ramped up its AI and machine lear...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyoncé wears colour-changing dress during co...</td>\n",
       "      <td>Singer Beyoncé wore a colour-changing dress d...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gauahar Khan, Zaid Darbar blessed with a baby boy</td>\n",
       "      <td>Actress Gauahar Khan and her husband Zaid Darb...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Complaint filed against Prabhas, Kriti Sanon's...</td>\n",
       "      <td>A complaint has been filed against Prabhas and...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yuzvendra Chahal creates history, takes most w...</td>\n",
       "      <td>RR leg-spinner Yuzvendra Chahal has created hi...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  WhatsApp responds to int'l calls scam, announc...   \n",
       "1  Beyoncé wears colour-changing dress during co...   \n",
       "2  Gauahar Khan, Zaid Darbar blessed with a baby boy   \n",
       "3  Complaint filed against Prabhas, Kriti Sanon's...   \n",
       "4  Yuzvendra Chahal creates history, takes most w...   \n",
       "\n",
       "                                             content  category  \n",
       "0  WhatsApp has ramped up its AI and machine lear...  national  \n",
       "1  Singer Beyoncé wore a colour-changing dress d...  national  \n",
       "2  Actress Gauahar Khan and her husband Zaid Darb...  national  \n",
       "3  A complaint has been filed against Prabhas and...  national  \n",
       "4  RR leg-spinner Yuzvendra Chahal has created hi...  national  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see top of notebook\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa85b8-d9b5-4b0c-a5e1-1d2d699bdd53",
   "metadata": {},
   "source": [
    "##### 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "481f0feb-c7c7-4025-9265-959d57fed86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "      <td>\\nCodeup is hosting a Women in Tech Panel in h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Rachel Rob...</td>\n",
       "      <td>\\nCodeup is hosting a Women in Tech Panel in h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women in Tech: Panelist Spotlight – Sarah Mellor</td>\n",
       "      <td>\\nCodeup is hosting a Women in Tech Panel in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women in Tech: Panelist Spotlight – Madeleine ...</td>\n",
       "      <td>\\nCodeup is hosting a Women in Tech Panel in h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Excellence in Tech: Panelist Spotlight –...</td>\n",
       "      <td>\\n\\nCodeup is hosting a Black Excellence in Te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Women in tech: Panelist Spotlight – Magdalena ...   \n",
       "1  Women in tech: Panelist Spotlight – Rachel Rob...   \n",
       "2   Women in Tech: Panelist Spotlight – Sarah Mellor   \n",
       "3  Women in Tech: Panelist Spotlight – Madeleine ...   \n",
       "4  Black Excellence in Tech: Panelist Spotlight –...   \n",
       "\n",
       "                                             content  \n",
       "0  \\nCodeup is hosting a Women in Tech Panel in h...  \n",
       "1  \\nCodeup is hosting a Women in Tech Panel in h...  \n",
       "2   \\nCodeup is hosting a Women in Tech Panel in ...  \n",
       "3  \\nCodeup is hosting a Women in Tech Panel in h...  \n",
       "4  \\n\\nCodeup is hosting a Black Excellence in Te...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see top of notebook\n",
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10e5c392-2064-422b-8f0a-7eead6729939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Codeup is hosting a Women in Tech Panel in honor of Women’s History Month on March 29th, 2023! To further celebrate, we’d like to spotlight each of our panelists leading up to the discussion to learn a bit about their respective experiences as women in the tech industry!\n",
      "\n",
      "Meet Magdalena!\n",
      "Magdalena Rahn is a current Codeup student in a Data Science cohort in San Antonio, Texas. She has a professional background in cross-cultural communications, international business development, the wine industry and journalism. After serving in the US Navy, she decided to complement her professional skill set by attending the Data Science program at Codeup; she is set to graduate in March 2023. Magdalena is fluent in French, Bulgarian, Chinese-Mandarin, Spanish and Italian.\n",
      "We asked Magdalena how Codeup impacted her career, and she replied “Codeup has provided a solid foundation in analytical processes, programming and data science methods, and it’s been an encouragement to have such supportive instructors and wonderful classmates.”\n",
      "Don’t forget to tune in on March 29th to sit in on an insightful conversation with Magdalena.\n"
     ]
    }
   ],
   "source": [
    "print(codeup_df.loc[0,'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72b10aec-246e-4f7d-a70f-bab5b5cc5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even though there is a newline character visible in the df,\n",
    "# when I print it it does not show up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f168e74f-f688-4074-b5e8-1961b6853108",
   "metadata": {},
   "source": [
    "##### 8. For each dataframe, produce the following columns:\n",
    "\n",
    "  - title to hold the title\n",
    "  - original to hold the original article/post content\n",
    "  - clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "  - stemmed to hold the stemmed version of the cleaned data.\n",
    "  - lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7ad9e0c-a998-4641-a887-3b1e89b80d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df = p.make_comparative_df(codeup_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5989f60a-43f9-4200-bdef-622d880e4c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = p.make_comparative_df(news_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708263da-e02d-490c-baf8-46d4f17715ae",
   "metadata": {},
   "source": [
    "##### 9. Ask yourself:\n",
    "\n",
    "  - If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "  - If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "  - If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68eb18-4f4f-4942-a01d-1811830e6908",
   "metadata": {},
   "source": [
    "For the first two, probably lemmatized. For the 200TB, probably stemmed unless you have the budget and the extra benefit seems worth the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9655f98c-dbaa-451c-b8f3-659ee55ce137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
